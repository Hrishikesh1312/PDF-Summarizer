# ðŸ§  PDF Summarizer (Local & Private) â€” using Ollama + PyQt5

A simple, privacy-focused desktop app to summarize one or more PDF files using LLMs â€” all running locally on your machine.

This project uses:

- ðŸ§  [Ollama](https://ollama.com) for local large language model inference
- ðŸ PyQt5 for a modern desktop user interface
- ðŸ“„ Support for **single or batch PDF summarization**
- ðŸŒ™ Toggle between dark mode and light mode
- ðŸ“‚ Export summaries as `.txt` files

---

## âš™ï¸ Requirements

> Ensure you have the following installed:

```bash
# Python dependencies
pip install PyQt5 fitz reportlab requests

# Ollama (for LLMs)
https://ollama.com/download

# Run your model of choice (e.g. LLaMA 3)
ollama run llama3
```

---

## ðŸš€ Getting Started

```bash
git clone https://github.com/yourusername/pdf-summarizer
cd pdf-summarizer

# Start Ollama model in a separate terminal
ollama run llama3

# Run the app
python main.py
```

---

## ðŸ›¡ï¸ Why Local?

This tool **never sends your PDF files or content to the cloud**.

âœ… Your PDFs are read and summarized **entirely on your system**\
âœ… Ollama runs the LLM **locally**, using models like `llama3`\
âœ… No API keys or internet needed after setup

---

## âœ¨ Features

- âœ… Load and summarize **one or many** PDF files at once
- âœ… Choose summary length (in number of sentences)
- âœ… Dark Mode / Light Mode toggle
- âœ… Export summaries as `.txt`
- âœ… Clean and responsive desktop UI
- âœ… 100% local â€” your documents never leave your device

---

## ðŸ‘¤ Screenshot

> *Add a screenshot of the app here for visual clarity*

---

## ðŸ“‚ Folder Structure

```
pdf-summarizer/
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ ui_main.py           # PyQt5 GUI
â”œâ”€â”€ summarizer.py        # PDF text extraction + Ollama integration
â””â”€â”€ README.md
```

---

## ðŸ§  Customizing the Model

You can change the model used by editing `summarizer.py`:

```python
def summarize_with_ollama(text, summary_length=5, model="llama3"):
```

Try other local models like `mistral`, `gemma`, etc. (see: `ollama list`)

---

## ðŸ“œ License

This project is open source and available under the [MIT License](LICENSE).

---

## ðŸ™Œ Acknowledgments

- [Ollama](https://ollama.com) â€” for blazing fast local LLMs
- [PyMuPDF](https://pymupdf.readthedocs.io/) â€” for fast and accurate PDF parsing
- [PyQt5](https://doc.qt.io/qtforpython/) â€” for beautiful UIs in Python

---

